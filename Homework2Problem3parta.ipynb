{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import timeit\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "#from cnn_utils import *\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#get mnist data, with one_hot encoding, reshape = False (that means images are not flatten)\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",reshape=False,one_hot=True)\n",
    "#suppress warnings\n",
    "tf.logging.set_verbosity(old_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train           = mnist.train.images, mnist.train.labels\n",
    "x_validation, y_validation = mnist.validation.images, mnist.validation.labels\n",
    "x_test, y_test             = mnist.test.images, mnist.test.labels\n",
    "\n",
    "#pad images with 0s (28x28 to 32x32)\n",
    "pad = 2\n",
    "x_train = np.pad(x_train, ((0,0), (pad,pad), (pad,pad), (0,0)), 'constant', constant_values = (0,0))\n",
    "x_validation = np.pad(x_validation, ((0,0), (pad,pad), (pad,pad), (0,0)), 'constant', constant_values = (0,0))\n",
    "x_test = np.pad(x_test, ((0,0), (pad,pad), (pad,pad), (0,0)), 'constant', constant_values = (0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 32, 32, 1)\n",
      "(55000, 10)\n",
      "(5000, 32, 32, 1)\n",
      "(5000, 10)\n",
      "(10000, 32, 32, 1)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (np.shape(x_train))\n",
    "print (np.shape(y_train))\n",
    "print (np.shape(x_validation))\n",
    "print (np.shape(y_validation))\n",
    "print (np.shape(x_test))\n",
    "print (np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_H0 -- scalar, height of an input image\n",
    "    n_W0 -- scalar, width of an input image\n",
    "    n_C0 -- scalar, number of channels of the input\n",
    "    n_y -- scalar, number of classes\n",
    "        \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (â‰ˆ2 lines)\n",
    "    X = tf.placeholder(tf.float32, [None, n_H0, n_W0, n_C0])\n",
    "    Y = tf.placeholder(tf.float32, [None, n_y])\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes weight parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [4, 4, 3, 8]\n",
    "                        W2 : [2, 2, 8, 16]\n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, W2\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                              # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 2 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [4,4,1,8], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W2 = tf.get_variable(\"W2\", [2,2,8,16], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"W2\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # CONV2D: stride of 1, padding 'SAME'\n",
    "    Z1 = tf.nn.conv2d(X, W1, strides = [1,1,1,1], padding = 'SAME')\n",
    "    # RELU\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    # MAXPOOL: window 8x8, sride 8, padding 'SAME'\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1,8,8,1], strides = [1,8,8,1], padding = 'SAME')\n",
    "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "    Z2 = tf.nn.conv2d(P1, W2, strides = [1,1,1,1], padding = 'SAME')\n",
    "    # RELU\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1,4,4,1], strides = [1,4,4,1], padding = 'SAME')\n",
    "    # FLATTEN\n",
    "    P2 = tf.contrib.layers.flatten(P2)\n",
    "    # FULLY-CONNECTED without non-linear activation function (not not call softmax).\n",
    "    # 6 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\" \n",
    "    Z3 = tf.contrib.layers.fully_connected(P2, 10, activation_fn = None)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.009,\n",
    "          num_epochs = 50, minibatch_size = 64, print_cost = True):\n",
    "    \n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of the correct shape\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(1e-4).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "     \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                sess.run(optimizer, feed_dict = {X: minibatch_X, Y: minibatch_Y})\n",
    "                _ , temp_cost = sess.run([optimizer, cost], feed_dict = {X: minibatch_X, Y: minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "                \n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "        \n",
    "        \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.argmax(Z3, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(accuracy)\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "                \n",
    "        return train_accuracy, test_accuracy, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 2.258855\n",
      "Cost after epoch 5: 0.577317\n",
      "Cost after epoch 10: 0.356060\n",
      "Cost after epoch 15: 0.280018\n",
      "Cost after epoch 20: 0.241013\n",
      "Cost after epoch 25: 0.216852\n",
      "Cost after epoch 30: 0.200045\n",
      "Cost after epoch 35: 0.187409\n",
      "Cost after epoch 40: 0.177925\n",
      "Cost after epoch 45: 0.170064\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 0.94945455\n",
      "Test Accuracy: 0.9487\n"
     ]
    }
   ],
   "source": [
    "_, _, parameters = model(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
