{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import  numpy as np\n",
    "from glob import glob\n",
    "from scipy import misc\n",
    "import os, cv2, random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogsAndCatsHelper:\n",
    "\n",
    "    @staticmethod\n",
    "    def get_data():\n",
    "        \n",
    "        TRAIN_DIR = 'C:/Users/Xiangyu Gao/Downloads/train/'\n",
    "        TEST_DIR = 'C:/Users/Xiangyu Gao/Downloads/test1/'\n",
    "\n",
    "        ROWS = 227\n",
    "        COLS = 227\n",
    "        CHANNELS = 3\n",
    "        print(os.listdir(TRAIN_DIR)[:5])\n",
    "        train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] # use this for full dataset\n",
    "        train_dogs =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'dog' in i]\n",
    "        train_cats =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'cat' in i]\n",
    "\n",
    "        test_images =  [TEST_DIR+i for i in os.listdir(TEST_DIR)]\n",
    "\n",
    "\n",
    "        # slice datasets for memory efficiency on Kaggle Kernels, delete if using full dataset\n",
    "        train_images = train_dogs[:] + train_cats[:]\n",
    "        random.shuffle(train_images)\n",
    "        test_images =  test_images[:]\n",
    "\n",
    "        def read_image(file_path):\n",
    "            img = cv2.imread(file_path, cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE\n",
    "            return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "        def prep_data(images):\n",
    "            count = len(images)\n",
    "            data = np.ndarray((count, CHANNELS, ROWS, COLS), dtype=np.uint8)\n",
    "\n",
    "            for i, image_file in enumerate(images):\n",
    "                image = read_image(image_file)\n",
    "                data[i] = image.T\n",
    "                if i%250 == 0: print('Processed {} of {}'.format(i, count))\n",
    "            \n",
    "            return data\n",
    "\n",
    "        train = prep_data(train_images[0:5000])\n",
    "        test = prep_data(test_images[0:5000])\n",
    "        train = np.swapaxes(train, 1,3)\n",
    "        test = np.swapaxes(test, 1,3)\n",
    "\n",
    "        print(\"Train shape: {}\".format(train.shape))\n",
    "        print(\"Test shape: {}\".format(test.shape))\n",
    "        labels = []\n",
    "        \n",
    "        for i in train_images:\n",
    "            if 'dog' in i.split('/')[-1]:\n",
    "                labels.append([1,0])\n",
    "            else:\n",
    "                labels.append([0,1])\n",
    "\n",
    "        #sns.countplot(labels).set_title('Cats and Dogs')\n",
    "        labels = np.array(labels[0:5000])\n",
    "\n",
    "        return train, labels, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet:\n",
    "\n",
    "    def __init__(self,\n",
    "                 batch_size = 32,\n",
    "                 epochs = 100):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch_size: number of examples per batch_size\n",
    "            epochs: number of iterations over all training examples\n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "\n",
    "    @staticmethod\n",
    "    def inference(images, num_classes):\n",
    "        \"\"\"Builds AlexNet Graph\n",
    "\n",
    "        Args:\n",
    "            images: train/test images\n",
    "            num_classes: number of classes\n",
    "        Returns:\n",
    "            final_node: last node in the graph\n",
    "        \"\"\"\n",
    "\n",
    "        # Layer 1\n",
    "        with tf.name_scope(\"conv1\") as scope:\n",
    "            kernel = AlexNetHelper.instintiate_weights('W1', [11, 11, 3, 96])\n",
    "            conv = tf.nn.conv2d(images, kernel, [1, 4, 4, 1], padding='SAME')\n",
    "            biases = AlexNetHelper.instintiate_bias('b1', [96])\n",
    "            conv1 = tf.nn.relu(tf.nn.bias_add(conv, biases), name=scope)\n",
    "\n",
    "        with tf.name_scope('batch_norm1') as scope:\n",
    "            mean, var = tf.nn.moments(conv1, [0, 1, 2])\n",
    "            batch_norm1 = tf.nn.batch_normalization(conv1, mean, var, 0, 1, 0, name=scope)\n",
    "\n",
    "        with tf.name_scope('pool1') as scope:\n",
    "            pool1 = tf.nn.max_pool(batch_norm1, [1, 3, 3, 1], [1, 2, 2, 1], padding='SAME', name=scope)\n",
    "\n",
    "        # Layer 2\n",
    "        with tf.name_scope(\"conv2\") as scope:\n",
    "            kernel = AlexNetHelper.instintiate_weights('W2', [5, 5, 96, 256])\n",
    "            conv = tf.nn.conv2d(pool1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = AlexNetHelper.instintiate_bias('b2', [256])\n",
    "            conv2 = tf.nn.relu(tf.nn.bias_add(conv, biases), name=scope)\n",
    "\n",
    "        with tf.name_scope('batch_norm2') as scope:\n",
    "            mean, var = tf.nn.moments(conv2, [0, 1, 2])\n",
    "            batch_norm2 = tf.nn.batch_normalization(conv2, mean, var, 0, 1, 0, name=scope)\n",
    "\n",
    "        with tf.name_scope('pool2') as scope:\n",
    "            pool2 = tf.nn.max_pool(batch_norm2, [1, 3, 3, 1], [1, 2, 2, 1], padding='SAME', name=scope)\n",
    "\n",
    "        # Layer 3\n",
    "        with tf.name_scope(\"conv3\") as scope:\n",
    "            kernel = AlexNetHelper.instintiate_weights('W3', [3, 3, 256, 384])\n",
    "            conv = tf.nn.conv2d(pool2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = AlexNetHelper.instintiate_bias('b3', [384])\n",
    "            conv3 = tf.nn.relu(tf.nn.bias_add(conv, biases), name=scope)\n",
    "\n",
    "        with tf.name_scope('batch_norm3') as scope:\n",
    "            mean, var = tf.nn.moments(conv3, [0, 1, 2])\n",
    "            batch_norm3 = tf.nn.batch_normalization(conv3, mean, var, 0, 1, 0, name=scope)\n",
    "\n",
    "        # Layer 4\n",
    "        with tf.name_scope(\"conv4\") as scope:\n",
    "            kernel = AlexNetHelper.instintiate_weights('W4', [3, 3, 384, 384])\n",
    "            conv = tf.nn.conv2d(batch_norm3, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = AlexNetHelper.instintiate_bias('b4', [384])\n",
    "            conv4 = tf.nn.relu(tf.nn.bias_add(conv, biases), name=scope)\n",
    "\n",
    "        with tf.name_scope('batch_norm4') as scope:\n",
    "            mean, var = tf.nn.moments(conv4, [0, 1, 2])\n",
    "            batch_norm4 = tf.nn.batch_normalization(conv4, mean, var, 0, 1, 0, name=scope)\n",
    "\n",
    "        # Layer 5\n",
    "        with tf.name_scope(\"conv5\") as scope:\n",
    "            kernel = AlexNetHelper.instintiate_weights('W5', [3, 3, 384, 256])\n",
    "            conv = tf.nn.conv2d(batch_norm4, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = AlexNetHelper.instintiate_bias('b5', [256])\n",
    "            conv5 = tf.nn.relu(tf.nn.bias_add(conv, biases), name=scope)\n",
    "\n",
    "        with tf.name_scope('batch_norm5') as scope:\n",
    "            mean, var = tf.nn.moments(conv5, [0, 1, 2])\n",
    "            batch_norm5 = tf.nn.batch_normalization(conv5, mean, var, 0, 1, 0, name=scope)\n",
    "\n",
    "        with tf.name_scope('pool5') as scope:\n",
    "            pool5 = tf.nn.max_pool(batch_norm5, [1, 3, 3, 1], [1, 2, 2, 1], padding='SAME', name=scope)\n",
    "\n",
    "        # Fully Connected 6\n",
    "        with tf.name_scope('FC6') as scope:\n",
    "            pool5_flat = tf.contrib.layers.flatten(pool5)\n",
    "            fc6 = tf.layers.dense(pool5_flat, units=4096, activation=tf.nn.relu, name=scope)\n",
    "            # fc6_dropout = tf.layers.dropout(fc6, 0.5)\n",
    "\n",
    "        with tf.name_scope('FC7') as scope:\n",
    "            fc7 = tf.layers.dense(fc6, units=4096, activation=tf.nn.relu, name=scope)\n",
    "            # fc7_dropout = tf.layers.dropout(fc7, 0.5)\n",
    "\n",
    "        with tf.name_scope('classes') as scope:\n",
    "            predictions = tf.layers.dense(fc7, units=num_classes, activation=tf.nn.softmax, name=scope)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runtime for AlexNet\n",
    "        :param\n",
    "        train_data: training data\n",
    "        num_classes: num_classes\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "\n",
    "        train_images, train_labels, valid_images= DogsAndCatsHelper.get_data()\n",
    "        num_classes = train_labels.shape[1]\n",
    "\n",
    "        images = tf.placeholder(tf.float32, shape=[None, *train_images[0].shape])\n",
    "        ph_labels = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "\n",
    "        predictions = self.inference(images, num_classes)\n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = predictions, labels = ph_labels))\n",
    "        #loss = tf.nn.l2_loss(tf.square(predictions - labels))\n",
    "        learner = tf.train.AdamOptimizer(0.001)\n",
    "        optimizer = learner.minimize(loss)\n",
    "\n",
    "        correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(ph_labels, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            for _ in range(self.epochs):\n",
    "                l_total = 0\n",
    "                acc = 0\n",
    "                for i in range(0, len(train_images), self.batch_size):\n",
    "                    l, acc, _ = sess.run(fetches=[loss, accuracy, optimizer],\n",
    "                                         feed_dict={images: train_images[i: self.batch_size + i],\n",
    "                                                    ph_labels: train_labels[i: self.batch_size + i]})\n",
    "                    l_total += np.sum(l)\n",
    "\n",
    "                    print(l_total, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNetHelper:\n",
    "    @staticmethod\n",
    "    def instintiate_weights(key, shape):\n",
    "        return tf.get_variable(key,\n",
    "                               shape=shape,\n",
    "                               initializer=tf.contrib.layers.variance_scaling_initializer(factor=2.0,\n",
    "                                                                                          mode='FAN_IN',\n",
    "                                                                                          uniform=False,\n",
    "                                                                                          seed=None,\n",
    "                                                                                          dtype=tf.float32))\n",
    "\n",
    "    @staticmethod\n",
    "    def instintiate_bias(key, shape):\n",
    "        return tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat.0.jpg', 'cat.1.jpg', 'cat.10.jpg', 'cat.100.jpg', 'cat.1000.jpg']\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-367d05f25ce0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0malex_net\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAlexNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0malex_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\Practical-Introduction-NN-hw\\hw2\\AlexNet.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \"\"\"\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_images\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mDogsAndCatsHelper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\Practical-Introduction-NN-hw\\hw2\\DogsAndCatsHelper.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\Practical-Introduction-NN-hw\\hw2\\DogsAndCatsHelper.py\u001b[0m in \u001b[0;36mprep_data\u001b[1;34m(images)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mprep_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCHANNELS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mROWS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCOLS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_file\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from AlexNet import AlexNet\n",
    "\n",
    "alex_net = AlexNet()\n",
    "alex_net.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
