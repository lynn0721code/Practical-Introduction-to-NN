{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.python.framework import ops\n",
    "#from cnn_utils import *\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: define a function to load traing batch data from directory\n",
    "def load_training_batch(folder_path,batch_id):\n",
    "    with open(folder_path + \"data_batch_\" + str(batch_id), 'rb') as fo:\n",
    "        train_dict = pickle.load(fo, encoding = 'latin1')\n",
    "    ###fetch features using the key ['data']###\n",
    "    features = train_dict['data']\n",
    "    ###fetch labels using the key ['labels']###\n",
    "    labels = train_dict['labels']\n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: define a function to load testing data from directory\n",
    "def load_testing_batch(folder_path):\n",
    "\n",
    "    ###load batch using pickle###\n",
    "    with open(folder_path + \"test_batch\", 'rb') as fo:\n",
    "        test_dict = pickle.load(fo, encoding = 'latin1')\n",
    "    ###fetch features using the key ['data']###\n",
    "    features = test_dict['data']\n",
    "    ###fetch labels using the key ['labels']###\n",
    "    labels = test_dict['labels']\n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: define a function that returns a list that contains label names (order is matter)\n",
    "\"\"\"\n",
    "    airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
    "\"\"\"\n",
    "def load_label_names():\n",
    "    label_List = np.array([\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"])\n",
    "    return label_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6: define a function that does min-max normalization on input\n",
    "def normalize(x):\n",
    "    return (x - x.min())/(x.max() - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 7: define a function that does one hot encoding on input\n",
    "def one_hot_encoding(x):\n",
    "    NUM_CLASSES = 10\n",
    "    one_hot_encoding_matrix = np.zeros([len(x), NUM_CLASSES])\n",
    "    #return np.eye(x.size)[x]\n",
    "    for i in range(0, len(x)):\n",
    "        one_hot_encoding_matrix[i, x[i]] = 1\n",
    "        \n",
    "    return one_hot_encoding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 8: define a function that perform normalization, one-hot encoding and save data using pickle\n",
    "def preprocess_and_save(features,labels,filename):\n",
    "    normal_feature = normalize(features)\n",
    "    one_hot_labels = one_hot_encoding(labels)\n",
    "    \n",
    "    preprocessed_dict = {'normal feature': normal_feature, 'one hot labels': one_hot_labels}\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(preprocessed_dict, handle, protocol = pickle.HIGHEST_PROTOCOL)  #Make sure about this operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 9:define a function that preprocesss all training batch data and test data. \n",
    "#Use 10% of your total training data as your validation set\n",
    "#In the end you should have 5 preprocessed training data, 1 preprocessed validation data and 1 preprocessed test data\n",
    "def preprocess_data(folder_path):\n",
    "    raw_train_data_feature1, raw_train_data_label1 = load_training_batch(folder_path,1)\n",
    "    raw_train_data_feature2, raw_train_data_label2 = load_training_batch(folder_path,2)\n",
    "    raw_train_data_feature3, raw_train_data_label3 = load_training_batch(folder_path,3)\n",
    "    raw_train_data_feature4, raw_train_data_label4 = load_training_batch(folder_path,4)\n",
    "    raw_train_data_feature5, raw_train_data_label5 = load_training_batch(folder_path,5)\n",
    "    \n",
    "    raw_test_data_feature, raw_test_data_label = load_testing_batch(folder_path)\n",
    "    \n",
    "    #build the validation data: 10% of 50000 = 5000\n",
    "    raw_validate_data_features = raw_train_data_feature1[0:5000, :]\n",
    "    raw_validate_data_label = raw_train_data_label1[0:5000]\n",
    "    preprocess_and_save(raw_train_data_feature1, raw_train_data_label1, 'processed_train1')\n",
    "    preprocess_and_save(raw_train_data_feature2, raw_train_data_label2, 'processed_train2')\n",
    "    preprocess_and_save(raw_train_data_feature3, raw_train_data_label3, 'processed_train3')\n",
    "    preprocess_and_save(raw_train_data_feature4, raw_train_data_label4, 'processed_train4')\n",
    "    preprocess_and_save(raw_train_data_feature5, raw_train_data_label5, 'processed_train5')\n",
    "    \n",
    "    preprocess_and_save(raw_test_data_feature, raw_test_data_label, 'processed_test')\n",
    "    \n",
    "    preprocess_and_save(raw_validate_data_features, raw_validate_data_label, 'processed_validate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder_path = '/home/jupyter/cifar-10-batches-py/'\n",
    "#preprocess_data(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(50000, 10)\n",
      "(5000, 3072)\n",
      "(10000, 3072)\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "valid_dict  = pickle.load(open('processed_validate','rb'))\n",
    "train_dict1 = pickle.load(open('processed_train1', 'rb'))\n",
    "train_dict2 = pickle.load(open('processed_train2', 'rb'))\n",
    "train_dict3 = pickle.load(open('processed_train3', 'rb'))\n",
    "train_dict4 = pickle.load(open('processed_train4', 'rb'))\n",
    "train_dict5 = pickle.load(open('processed_train5', 'rb'))\n",
    "test_dict   = pickle.load(open('processed_test', 'rb'))\n",
    "\n",
    "valid_features = valid_dict['normal feature']\n",
    "valid_labels   = valid_dict['one hot labels']\n",
    "\n",
    "train_features1 = train_dict1['normal feature']\n",
    "train_labels1   = train_dict1['one hot labels']\n",
    "train_features2 = train_dict1['normal feature']\n",
    "train_labels2   = train_dict1['one hot labels']\n",
    "train_features3 = train_dict1['normal feature']\n",
    "train_labels3   = train_dict1['one hot labels']\n",
    "train_features4 = train_dict1['normal feature']\n",
    "train_labels4   = train_dict1['one hot labels']\n",
    "train_features5 = train_dict1['normal feature']\n",
    "train_labels5   = train_dict1['one hot labels']\n",
    "\n",
    "test_features   = test_dict['normal feature']\n",
    "test_labels     = test_dict['one hot labels']\n",
    "\n",
    "totalX = np.concatenate((train_features1,train_features2,train_features3,train_features4,train_features5))\n",
    "totalY = np.concatenate((train_labels1,train_labels2,train_labels3,train_labels4,train_labels5))\n",
    "#Check\n",
    "print(np.shape(totalX))\n",
    "print(np.shape(totalY))\n",
    "print(np.shape(valid_features))\n",
    "print(np.shape(test_features))\n",
    "#Reshape\n",
    "totalX = np.reshape(totalX, (50000,32,32,3))\n",
    "print(np.shape(totalX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n",
      "(5000, 32, 32, 3)\n",
      "(5000, 10)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n",
      "(1000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = totalX\n",
    "y_train = totalY\n",
    "x_validation = np.reshape(valid_features, (5000,32,32,3))\n",
    "y_validation = valid_labels\n",
    "x_test = np.reshape(test_features, (10000,32,32,3))\n",
    "y_test = test_labels\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(x_validation))\n",
    "print(np.shape(y_validation))\n",
    "print(np.shape(x_test))\n",
    "print(np.shape(y_test))\n",
    "\n",
    "mini_batch1 = x_train[0:1000,:]\n",
    "print(np.shape(mini_batch1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_H0 -- scalar, height of an input image\n",
    "    n_W0 -- scalar, width of an input image\n",
    "    n_C0 -- scalar, number of channels of the input\n",
    "    n_y -- scalar, number of classes\n",
    "        \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (â‰ˆ2 lines)\n",
    "    X = tf.placeholder(tf.float32, [None, n_H0, n_W0, n_C0])\n",
    "    Y = tf.placeholder(tf.float32, [None, n_y])\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes weight parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [4, 4, 3, 8]\n",
    "                        W2 : [2, 2, 8, 16]\n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, W2\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                              # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 2 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [5,5,3,8], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W2 = tf.get_variable(\"W2\", [2,2,8,16], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"W2\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # CONV2D: stride of 1, padding 'SAME'\n",
    "    Z1 = tf.nn.conv2d(X, W1, strides = [1,1,1,1], padding = 'SAME')\n",
    "    # RELU\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    # MAXPOOL: window 8x8, sride 8, padding 'SAME'\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1,2,2,1], strides = [1,1,1,1], padding = 'SAME')\n",
    "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "    Z2 = tf.nn.conv2d(P1, W2, strides = [1,1,1,1], padding = 'SAME')\n",
    "    # RELU\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1,2,2,1], strides = [1,1,1,1], padding = 'SAME')\n",
    "    # FLATTEN\n",
    "    P2 = tf.contrib.layers.flatten(P2)\n",
    "    # FULLY-CONNECTED without non-linear activation function (not not call softmax).\n",
    "    # 10 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\" \n",
    "    Z3 = tf.contrib.layers.fully_connected(P2, 10, activation_fn = None)\n",
    "    #Z4 = tf.contrib.layers.fully_connected(Z3, 84, activation_fn = tf.nn.relu)\n",
    "    #Z5 = tf.contrib.layers.fully_connected(Z4, 10, activation_fn = None)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    #permutation = list(np.random.permutation(m))\n",
    "    #shuffled_X = X[permutation,:,:,:]\n",
    "    #shuffled_Y = Y[permutation,:]\n",
    "    #Try not shuffling:\n",
    "    shuffled_X = X\n",
    "    shuffled_Y = Y\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 15, minibatch_size = 128, print_cost = True):\n",
    "    \n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of the correct shape\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "     \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            #seed = seed + 1\n",
    "            #minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "            #print(num_minibatches)\n",
    "            for k in range(num_minibatches - 1):\n",
    "\n",
    "                # Select a minibatch\n",
    "                #(minibatch_X, minibatch_Y) = minibatch\n",
    "                minibatch_X = X_train[k * minibatch_size : k * minibatch_size + minibatch_size,:,:,:]\n",
    "                minibatch_Y = Y_train[k * minibatch_size : k * minibatch_size + minibatch_size,:]\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                sess.run(optimizer, feed_dict = {X: minibatch_X, Y: minibatch_Y})\n",
    "                _ , temp_cost = sess.run([optimizer, cost], feed_dict = {X: minibatch_X, Y: minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "                \n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "            if epoch % 1 == 0:\n",
    "                # Calculate the correct predictions\n",
    "                predict_op = tf.argmax(Z3, 1)\n",
    "                correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "\n",
    "                # Calculate accuracy on the test set\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "                #print(accuracy)\n",
    "                #train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "                test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "                #print(\"Train Accuracy:\", train_accuracy)\n",
    "                print(\"Test Accuracy during Training:\", test_accuracy)\n",
    "        \n",
    "        \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.argmax(Z3, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        #print(accuracy)\n",
    "        #train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        #print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Training is finished\")\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "                \n",
    "        return test_accuracy, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.772527\n",
      "Test Accuracy during Training: 0.4413\n",
      "Cost after epoch 1: 1.447033\n",
      "Test Accuracy during Training: 0.4715\n",
      "Cost after epoch 2: 1.340347\n",
      "Test Accuracy during Training: 0.484\n",
      "Cost after epoch 3: 1.263813\n",
      "Test Accuracy during Training: 0.4906\n",
      "Cost after epoch 4: 1.198053\n",
      "Test Accuracy during Training: 0.4967\n",
      "Cost after epoch 5: 1.138548\n",
      "Test Accuracy during Training: 0.5024\n",
      "Cost after epoch 6: 1.083593\n",
      "Test Accuracy during Training: 0.5093\n",
      "Cost after epoch 7: 1.032157\n",
      "Test Accuracy during Training: 0.5137\n",
      "Cost after epoch 8: 0.983623\n",
      "Test Accuracy during Training: 0.517\n",
      "Cost after epoch 9: 0.937530\n",
      "Test Accuracy during Training: 0.5192\n",
      "Cost after epoch 10: 0.893507\n",
      "Test Accuracy during Training: 0.5225\n",
      "Cost after epoch 11: 0.851296\n",
      "Test Accuracy during Training: 0.5243\n",
      "Cost after epoch 12: 0.810629\n",
      "Test Accuracy during Training: 0.5239\n",
      "Cost after epoch 13: 0.771384\n",
      "Test Accuracy during Training: 0.5228\n",
      "Cost after epoch 14: 0.733405\n",
      "Test Accuracy during Training: 0.5215\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VPW9//HXJwuELeyEJCxhXwQSBUUQFIuiIot1q9VatVqL1q7eX6+9t/e2t9729mp7ra21Vi1i3aoVlUVUXFCsgBiWsAoia0iAsO+EJJ/fHzPQNGYDMjkzmffz8ZhHZs75njOfA8m853zPOd9j7o6IiAhAQtAFiIhI9FAoiIjISQoFERE5SaEgIiInKRREROQkhYKIiJykUJAGwczeMLNbgq5DJNYpFOSMmNlGM7sk6Drc/Qp3fzroOgDM7H0zu6Me3qexmU02s/1mts3MflhD+x+E2+0PL9e43LwsM5tjZofN7NOK/6c1LHu/mS03sxIz+1mdb6jUK4WCRD0zSwq6hhOiqRbgZ0AvoCtwMfAjM7u8soZmdhlwHzA63L478F/lmrwALAHaAv8OvGxm7Wu57DrgR8DrdbRdEiR310OP034AG4FLqpg3DlgK7AXmAYPKzbsP+Bw4AKwCvlxu3q3AR8BDwC7gv8PT/g78GtgDbACuKLfM+8Ad5Zavrm03YG74vd8B/gA8W8U2jALygX8FtgHPAK2BmUBReP0zgU7h9r8ASoGjwEHgkfD0vsDbwG5gDXB9HfzbFwBjyr2+H/hrFW2fB35Z7vVoYFv4eW/gGNCi3PwPgUk1LVvhPZ4Ffhb076QeZ/bQnoJEhJmdDUwGvkXo2+efgOnluh0+B0YCLQl963zWzNLLrWIosB5II/RBe2LaGqAd8ADwZzOzKkqoru3zwMJwXT8Dbq5hczoCbQh9S76T0B72U+HXXYAjwCMA7v7vhD5Q73H35u5+j5k1IxQIzwMdgBuAR82sf2VvZmaPmtneKh7Lwm1aA+lAXrlF84CzqtiGsyppm2ZmbcPz1rv7gSrWVd2y0sAoFCRS7gT+5O4fu3uph/r7jwHnA7j739y9wN3L3P1F4DPgvHLLF7j77929xN2PhKdtcvcn3L0UeJrQh2JaFe9faVsz6wKcC/ynuxe7+9+B6TVsSxnwU3c/5u5H3H2Xu09198PhD9JfABdVs/w4YKO7PxXeniXAVOC6yhq7+93u3qqKx6Bws+bhn/vKLboPaFFFDc0raUu4fcV5FddV3bLSwCgUJFK6AveW/5YLdAYyAMzs62a2tNy8AYS+1Z+wpZJ1bjvxxN0Ph582r6RddW0zgN3lplX1XuUVufvREy/MrKmZ/cnMNpnZfkJdUa3MLLGK5bsCQyv8W9xEaA/kdB0M/0wtNy2VUJdYVe0rtiXcvuK8iuuqbllpYBQKEilbgF9U+Jbb1N1fMLOuwBPAPUBbd28FrADKdwVFavjeQqCNmTUtN61zDctUrOVeoA8w1N1TgQvD062K9luADyr8WzR397sqezMze8zMDlbxWAng7nvC25JdbtFsYGUV27Cykrbb3X1XeF53M2tRYf7KWiwrDYxCQepCspmllHskEfrQn2RmQy2kmZldGf7gaUbog7MIwMxuI7SnEHHuvgnIBX5mZo3MbBgw/hRX04LQcYS9ZtYG+GmF+dsJnaFzwkygt5ndbGbJ4ce5ZtavihonhUOjskf5YwZ/AX5iZq3NrC/wTWBKFTX/BbjdzPqbWSvgJyfauvtaQicE/DT8//dlYBChLq5qlwUIb08Koc+TpPA6qtprkiinUJC6MIvQh+SJx8/cPZfQh9QjhM7QWUforCDcfRXwG2A+oQ/QgYTONqovNwHD+MeZTS8SOt5RW78FmgA7gQXAmxXmPwxca2Z7zOx34eMOYwgdYC4g1LX1v0BjzsxPCR2w3wR8ADzo7m8CmFmX8J5FF4Dw9AeAOcDm8DLlw+wGYAih/6tfAde6e1Etl32C0P/7VwmdznqEmg/eS5Qyd91kR+Kbmb0IfOruFb/xi8Qd7SlI3Al33fQws4TwxV4TgdeCrkskGkTT1Zki9aUj8Aqh6xTygbvCp4mKxD11H4mIyEnqPhIRkZNirvuoXbt2npWVFXQZIiIxZdGiRTvdvX1N7WIuFLKyssjNzQ26DBGRmGJmm2rTLmLdR+Ex13eY2Yoq5rc0sxlmlmdmK8MXMImISIAieUxhClDp2O5h3wZWuXs2oeGJf2NmjSJYj4iI1CBioeDucwmNHV9lE6BFeDjj5uG2JZGqR0REahbk2UePAP0IXfa/HPieu5dV1tDM7jSzXDPLLSoqqs8aRUTiSpChcBmhQbgygBzgETOrOHwvAO7+uLsPcfch7dvXePBcREROU5ChcBvwioesI3TLxL4B1iMiEveCDIXNhO71ipmlERqffn2A9YiIxL1InpL6AqGhkfuYWb6Z3W5mk8xsUrjJ/cBwM1sOvAv8q7vvjFQ963Yc4OczVlFcUulhCxERIYIXr7n7V2uYX0BojPl6sWX3ESZ/tIHhPdpySf+qbusrIhLf4mbsoxG92tG6aTLT8gqCLkVEJGrFTSgkJyYwdmA6b6/axqFjuhxCRKQycRMKABNzMjl6vIy3V20PuhQRkagUV6EwpGtrMlqmMG3p1qBLERGJSnEVCgkJxvicDOZ+tpNdB0/lPu0iIvEhrkIBYGJ2JqVlzqwV24IuRUQk6sRdKPRLb0GvDs2Zri4kEZEviLtQMDMm5mTwycY9bN17JOhyRESiStyFAsCE7EwAZuiaBRGRfxKXodClbVPO7tKKaUsVCiIi5cVlKABMyM5gdeF+1m4/EHQpIiJRI25D4cpB6SQYTNfegojISXEbCh1apHBBz3ZMy9uKuwddjohIVIjbUIBQF9KW3UdYsmVv0KWIiESFuA6FywZ0pFFSgrqQRETC4joUUlOSGd23AzOXFVJSqpvviIjEdSgATMzJYOfBY8xfvyvoUkREAhf3oTCqTwdaNE7SNQsiIigUSElO5LIBHXlzxTaOHi8NuhwRkUDFfShAqAvp4LES5ny6I+hSREQCpVAAhnVvS7vmjdWFJCJxT6EAJCUmMG5QOu+t2cG+I8eDLkdEJDAKhbCJORkUl5Tx1krdfEdE4pdCISyncyu6tGmqC9lEJK4pFMJO3Hxn3uc72XHgaNDliIgEQqFQzsScDMocXl9WGHQpIiKBUCiU07NDC/qnp+osJBGJWwqFCibkZLB0y1427ToUdCkiIvVOoVDB+OwMQDffEZH4FLFQMLPJZrbDzFZU02aUmS01s5Vm9kGkajkVma2acF5WG15bqpvviEj8ieSewhTg8qpmmlkr4FFggrufBVwXwVpOyYScDD4vOsSqwv1BlyIiUq8iFgruPhfYXU2TG4FX3H1zuH3UDDw0dmA6SQmmLiQRiTtBHlPoDbQ2s/fNbJGZfb2qhmZ2p5nlmlluUVFRxAtr06wRF/Zuz4y8AsrK1IUkIvEjyFBIAgYDVwKXAf9hZr0ra+juj7v7EHcf0r59+3opbmJOBgX7jpK7aU+9vJ+ISDQIMhTygbfc/ZC77wTmAtkB1vNPLumXRpPkRKYt3Rp0KSIi9SbIUJgGjDCzJDNrCgwFVgdYzz9p1jiJS/un8fryQopLdP9mEYkPkTwl9QVgPtDHzPLN7HYzm2RmkwDcfTXwJrAMWAg86e5Vnr4ahAnZGew9fJy/r4v8cQwRkWiQFKkVu/tXa9HmQeDBSNVwpi7s3Z6WTZKZtrSAL/VNC7ocEZGI0xXN1WiUlMDYgenMXrmdw8UlQZcjIhJxCoUaTMzJ4MjxUt5etT3oUkREIk6hUIPzstrQMTVFF7KJSFxQKNQgIcGYkJPBB2uL2HOoOOhyREQiSqFQCxOyMygpc95Yofs3i0jDplCohbMyUunRvpkuZBORBk+hUAtmxoTsTBZu3E3B3iNBlyMiEjEKhVqakJOBO8xcpgPOItJwKRRqqVu7ZmR3aqn7N4tIg6ZQOAUTcjJZWbCfdTsOBF2KiEhEKBROwfhB6Zjp/s0i0nApFE5Bh9QUhvdoy/S8At2/WUQaJIXCKZqYncnGXYdZlr8v6FJEROqcQuEUXTagI40SE3TAWUQaJIXCKWrZJJmL+7ZnxrICSnX/ZhFpYBQKp2FCdiZFB46xYP2uoEsREalTCoXTMLpfB5o10v2bRaThUSichpTkRC4b0JE3Vmzj6PHSoMsREakzCoXTNDEnkwNHS3h/je7fLCINh0LhNF3Qoy1tmzViRp7OQhKRhkOhcJqSEhMYNyidd1Zv58DR40GXIyJSJxQKZ2BCTibHSsqYvVL3bxaRhkGhcAbO6dKKTq2b8PKifA17ISINgkLhDJgZtwzLYv76Xdw3dbkuZhORmJcUdAGx7o6R3Thw9Di/e28d+48e57c35NA4KTHoskRETov2FM6QmfHDMX34yZX9eGPFNu54OpfDxSVBlyUicloUCnXkjpHdeeCaQXy0bic3/3kh+w7rjCQRiT0KhTp0/bmd+cON57A8fx9feXw+RQeOBV2SiMgpUSjUsSsGpvPnW4ewaddhrntsHlt2Hw66JBGRWotYKJjZZDPbYWYramh3rpmVmNm1kaqlvo3s1Z5n7xjK7kPFXPfYfN3TWURiRiT3FKYAl1fXwMwSgf8FZkewjkAM7tqaF781jJIy57rH5rMsf2/QJYmI1ChioeDuc4HdNTT7DjAV2BGpOoLULz2VlycNo1njJG584mPdf0FEol5gxxTMLBP4MvDHWrS908xyzSy3qCi2RiXNateMlycNp2PLFG6ZvJB3V2tIDBGJXkEeaP4t8K/uXlZTQ3d/3N2HuPuQ9u3b10NpdatjyxRe+tYw+nRswZ3PLOK1Jbo5j4hEpyBDYQjwVzPbCFwLPGpmVwVYT0S1adaI5+4YyrlZrfnBS0t5Zv7GoEsSEfmCwELB3bu5e5a7ZwEvA3e7+2tB1VMfWqQkM+W28xjdtwP/MW0lf5izTgPpiUhUieQpqS8A84E+ZpZvZreb2SQzmxSp94wFKcmJ/PFrg/ny2Zk8+NYa/ueNTxUMIhI1IjYgnrt/9RTa3hqpOqJRcmICv7kumxYpSTw+dz37Dh/nl1cPJDHBgi5NROKcRkkNSEKC8V8TzqJlk2R+/946Dhw7zkNf0QirIhIshUKAzIx7x/ShZZNk/vv11Rw4msufbh5M00b6bxGRYGjsoyjwhRFWj2iEVREJhkIhSpwYYXVZ/l5ueHyBRlgVkUAoFKLIFQPT+fMt57Jx5yGNsCoigVAoRJkLe7fn2TvOY/ehYsb+7kNeyt2iU1ZFpN4oFKLQ4K5tmH7PCPp2bMGPXl7GN6Z8wrZ9R4MuS0TigEIhSmW1a8aLdw7jP8b1Z/76XYx56AOmLsrXXoOIRJRCIYolJBi3j+jGG9+7kN5pLbj3b3l88y+57NivvQYRiQyFQgzo1q4ZL35rGD+5sh8ffraTSx+ay2tLtmqvQUTqnEIhRiQmGHeM7M6s742kR/tmfP/Fpdz5zCJ2HNBeg4jUHYVCjOnRvjl/mzScfxvblw/WFjHmoblMW6q9BhGpGwqFGJSYYNx5YQ9mfXckWW2b8b2/LmXSs4t0wZuInDGFQgzr2aE5U+8azn1X9GXOmiLGPPQBM5cVBF2WiMSwWoWCmV1Xm2lS/xITjEkX9eD174ygS5um3PP8Eu5+bhE7D2qvQUROXW33FH5cy2kSkF5pLZh613B+dHkf3lm1gzEPzeX1ZYVBlyUiMabaMZrN7ApgLJBpZr8rNysVKIlkYXLqkhITuHtUTy7pl8a9L+Xx7ecXM2tFOvdPHECbZo2CLk9EYkBNewoFQC5wFFhU7jEduCyypcnp6p3WglfvHs7/u6wPs1duY8xDH/DmCu01iEjNrDanMppZsrsfDz9vDXR292WRLq4yQ4YM8dzc3CDeOiZ9um0///K3PFZs3c/47Ax+PuEsWmuvQSTumNkidx9SU7vaHlN428xSzawNsBh4wsweOqMKpV707ZjKq3dfwL2X9ubNFYVc+tAHuhpaRKpU21Bo6e77gauBv7j7UGB05MqSupScmMB3Rvdi+j0jyGjVhO+/uJSr/ziPpVv2Bl2aiESZ2oZCkpmlA9cDMyNYj0RQv/RUXrv7Ah64dhD5e45w1R8+4ocvLWW7BtgTkbDahsLPgbeAz939EzPrDnwWubIkUhISjOuHdGbOv4zirlE9mJlXyMW/fp9H3vuMo8dLgy5PRAJWqwPN0UQHmuvW5l2H+cWsVby1cjudWjfh38b244oBHTGzoEsTkTpUpweazayTmb1qZjvCj6lm1unMy5SgdWnblD/dPITnvzmU5o2TuPu5xdzw+AJWFuwLujQRCUBtu4+eInRtQkb4MSM8TRqI4T3a8fp3R/KLLw/gsx0HGff7v/PjV5ZpuAyROFPb6xSWuntOTdPqg7qPIm/fkeP87t3PeHreRpokJ/Ld0b24ZXgWjZI0fqJIrKrr6xR2mdnXzCwx/PgasOvMSpRo1bJJMv8xrj9vfv9ChmS15hezVnPZb+fyzqrtur5BpIGrbSh8g9DpqNuAQuBa4NYI1SRRomeH5jx123k8ddu5JBjc8Zdcvj55IWu3Hwi6NBGJkFM5JfUWd2/v7h0IhcR/VbeAmU0OH5ReUcX8m8xsmZktN7N5ZpZ9aqVLfbm4Twfe/P6F/Oe4/uRt2csVD3/IT6etYO/h4qBLE5E6VttQGOTue068cPfdwNk1LDMFuLya+RuAi9x9IHA/8Hgta5EAJCcm8I0R3Xj//13Mjed14ZkFm7jowfd5et5GSkrLgi5PROpIbUMhITwQHgDhMZCqHXbb3ecCu6uZP69c0CwAdIprDGjTrBH3XzWAWd8byYDMVH46fSVXPPwhc9cWBV2aiNSB2obCb4D5Zna/md0PzAMeqMM6bgfeqGqmmd1pZrlmlltUpA+faNC3YyrP3j6Ux28eTHFpGV+fvJAbn1jA4s17al5YRKJWra9oNrP+wJfCL99z91W1WCYLmOnuA6ppczHwKDDC3Ws8o0mnpEafYyWlPLdgM4++v46dB4u5pF8HfnhpH/pnpAZdmoiE1faU1IgOc1FTKJjZIOBV4Ap3X1ubdSoUotehYyVMmbeRP33wOfuPljBuUDo/uLQ3Pdo3D7o0kbhX19cp1Dkz6wK8Atxc20CQ6NascRLfvrgnH/7rl7jn4p689+kOLv2/D/jRy3nk7zkcdHkiUgsR21MwsxeAUUA7YDvwUyAZwN0fM7MngWuATeFFSmqTYtpTiB07Dx7j0Tmf8+zHm8Dhq+d15ttf6kmHFilBlyYSd6Ki+ygSFAqxp2DvEX7/3jpeyt1CcqJx6/BuTLqoO62a6ragIvVFoSBRZ+POQ/z2nbVMyyugeaMkvnlhd74xohvNG1d7drOI1AGFgkStNdsO8JvZa5i9ajttmjXirot6cPOwrqQkJwZdmkiDpVCQqJe3ZS+/nr2GDz/bSVpqY77zpV5cP6SzRmMViQCFgsSMBet38eu31pC7aQ+d2zTh+6N7c9XZmSQm6O5vInUl6k9JFTnh/O5t+dukYTx127mkpiRz79/yuPy3c3ljeaGG6hapZwoFiQpmxsV9OjDjnhE8etM5OHDXc4u58nd/543lhZSVKRxE6oO6jyQqlZY5ry3ZyiNz1rFh5yF6dmjO3aN6MCE7g6REfZcROVU6piANQmmZM2t5IX+Ys45Ptx2gc5smTLqoB9cO7kTjJJ2tJFJbCgVpUNydd1fv4Pdz1pG3ZS9pqY355sju3Di0C00b6ToHkZooFKRBcnc+WreLR+Z8xoL1u2nTrBG3j+jGzcO6kpqSHHR5IlFLoSAN3qJNu3nkvXXMWVNEi5QkbhmWxTdGdKNNMw2fIVKRQkHixoqt+3j0/XW8sWIbKUmJ3Di0C3de2J20VA28J3KCQkHizrodB3h0zudMyysg0Yxrh3Tirot60LlN06BLEwmcQkHi1uZdh3ls7ue8nJtPqTsTczK4e1RPenbQzX4kfikUJO5t23eUJz5cz3Mfb+JYSRlXDOjI3aN6MiCzZdClidQ7hYJI2K6Dx5j80Qb+Mm8TB46VcHGf9tx9cU+GdG2NmcZXkvigUBCpYN+R4zwzfyOTP9rI7kPFZHduxTdHduPyszrqKmlp8BQKIlU4UlzKy4vz+fOH69m46zCdWjfhtgu68ZVzO+uGP9JgKRREalBa5ryzejtPfrieTzbuoUVKEjcO7cKtw7NIb9kk6PJE6pRCQeQULNm8hyc/3MAbKwpJMGN8dgZ3jOzGWRk6KC0Ng0JB5DRs2X2YyR9t4MVPtnC4uJQLerbljpHdGdW7vQ5KS0xTKIicgX1HjvPCws089dEGtu8/Rq8OzbljZDcm5mTqXtISkxQKInWguKSMmcsKeOLDDawu3E+75o25ZVhXvnZ+V1prjCWJIQoFkTrk7sz7fBePz13PB2uLSElO4NrBnbh9RHe6tWsWdHkiNaptKOj8O5FaMDMu6NmOC3q2Y+32Azz54Xpe+iSf5z7ezKX90vjmhd11MZw0CNpTEDlNOw4c5Zn5m3hmwSb2Hj5OdudWfOOCLK4YkE6jJF0MJ9FF3Uci9eRwcQlTF+Uz+aONbNh5iPYtGnPjeV24aWgXOmj4bokSCgWRelZW5sz9rIin521kzpoikhKMKwamc+vwrpzTRV1LEiwdUxCpZwkJxqg+HRjVpwMbdx7imQWbeCl3CzPyChiQmcrXh2UxITtDp7RKVIvYnoKZTQbGATvcfUAl8w14GBgLHAZudffFNa1XewoSSw4dK+HVJVv5y/yNrN1+kNZNk7nhvC587fyuZLbSUBpSfwLvPjKzC4GDwF+qCIWxwHcIhcJQ4GF3H1rTehUKEovcnfnrd/H0vI28vWo7AJf2T+OW4VkM695WXUsScYF3H7n7XDPLqqbJREKB4cACM2tlZunuXhipmkSCYmYM79GO4T3akb/nMM8u2MxfP9nMWyu30zutOV8flsXV52TStJF6dCVYQZ43lwlsKfc6PzztC8zsTjPLNbPcoqKieilOJFI6tW7KfVf0ZcGPR/PAtYNITkzgJ6+tYOgv3+X+mavYuPNQ0CVKHIuJryXu/jjwOIS6jwIuR6ROpCQncv2Qzlw3uBOLN+9hyrxNPD1vI5M/2sCo3u25ZXgWF/ZqT0KCupak/gQZCluBzuVedwpPE4krZsbgrm0Y3LUN26/sx/Mfb+a5jzdz61Of0K1dM24+vyvXnNOJlk2Tgy5V4kCQ3UfTga9byPnAPh1PkHiXlprCDy7tzbz7vsTDN+TQqmkyP5+5ivN++Q73vpTH4s17iLVriyS2RGxPwcxeAEYB7cwsH/gpkAzg7o8BswidebSO0Cmpt0WqFpFY0ygpgYk5mUzMyWTF1n08v3Az05ZsZerifPp2bMFNQ7tw1dmZtEjR3oPULV3RLBIjDh4rYdrSrTz/8WZWFuynSXIiE3MyuHFoFwZ1ahV0eRLlAr9OIVIUChLv3J28/H08//EmZuQVcuR4KQMyU7nxvK5MzMmgWeOYOH9E6plCQSQO7D96nNeWhPYePt12gOaNk07uPej+0lKeQkEkjrg7izfv4bmPN/P6skKOlZSR3bkVNw3twvhBGTRppPGW4p1CQSRO7T1czNTFW3n+4018XnSIFilJXH12JjcO7Uqfji2CLk8ColAQiXPuzsINu3l+4WbeWL6N4tIyhnRtzY1DuzB2YLpGa40zCgUROWn3oWJeXrSFFxZuYcPOQ7RskszV52TylXM707djatDlST1QKIjIF5SVOQvW7+K5jzcze9U2jpc62Z1act2QzkzIySBV1z00WAoFEanWroPHeG1pAS99soU12w+QkpzA2AHpXDekM+d3b6PhvBsYhYKI1Iq7syx/Hy/mbmHG0gIOHCuha9umXD+kM9ec04mOLXWf6YZAoSAip+xIcSlvrCjkpdwtLFi/mwSDi3q35/ohnRndL41GSUEOlyZnQqEgImdk485D/G3RFl5elM/2/cdo26wRXz47k+vP7UzvNJ3aGmsUCiJSJ0rLnLlri3gpdwvvrN7O8VInp3MrvnJuZ8YNStegfDFCoSAidW7XwWO8umQrL36yhc92HKRJciJjB6Zz/ZBOnNdNB6ejmUJBRCLG3Vm6ZS8v5eYzI6+Ag8dKyGrblOuGdObawZ1IS9XB6WijUBCRenG4uIQ3lm/jxdwtLNwQOjh9Qc92XDu4E2P6d9S4S1FCoSAi9W7DzkO8ujifqYu3snXvEZo3TmLswI5cc04nzs1qo/tNB0ihICKBKStzPt6wm1cW5zNreSGHikvp1LoJV5/TiavPziSrXbOgS4w7CgURiQqHi0uYvXI7Uxfn8/d1O3GHIV1bc/U5nbhyUDotm+jspfqgUBCRqFO47wivLSlg6uJ81u04SKOkBMb0T+Oaczoxslc7khJ1cVykKBREJGq5O8u37mPqonym5xWw5/Bx2jVvzFU5GVwzuBP90jVya11TKIhITCguKWPOmh1MXZTPnDU7OF7q9EtP5ZpzMpmYk0n7Fo2DLrFBUCiISMzZfaiYGXkFvLI4n7z8fSQmGBf1bs/V52RySb803RjoDCgURCSmfbb9AK8s2cqri7eybf9RWjRO4vIBHbnq7EzO796WRJ3eekoUCiLSIJSWOfM/38VrS7fy5optHDxWQlpqY8YPyuCqszM5KyNVw2vUgkJBRBqco8dLeXf1Dl5bupX3w8cferRvxlU5oeMPXdo2DbrEqKVQEJEGbe/hYmYt38ZrS7eycMNuAAZ3bc1VORlcOSiDNs0aBVxhdFEoiEjcyN9zmOl5BUxbUsCa7QdISjAu7N2eiTkZGn8pTKEgInFpdeF+Xlu6lelLCyjcd5SmjRK57KyOTMzJYETP+L1ATqEgInGtrMxZuHE305Zu5fVlhew/WkK75o0YFz5And2pZVwdoI6KUDCzy4GHgUTgSXf/VYX5XYCngVbhNve5+6zq1qlQEJFTdayklPfXFDFt6VbeWb2D4pIysto2ZWJOJuOzM+jZoXnQJUZc4KFgZonAWuBSIB/4BPiqu68q1+ZxYIm7/9HM+gOz3D2ruvUqFETkTOw/epw3V2xj2tKqfCD/AAALrElEQVStzPt8F+7QLz2V8dnpjB+UQec2DfMMptqGQlIEazgPWOfu68MF/RWYCKwq18aBE4OctAQKIliPiAipKclcP6Qz1w/pzI79R3l9eSEz8gp44M01PPDmGnI6t2J8dgZXDkynY8v4u4NcJPcUrgUud/c7wq9vBoa6+z3l2qQDs4HWQDPgEndfVMm67gTuBOjSpcvgTZs2RaRmEYlfW3Yf5vXlhcxcVsCKrfsxg/Oy2jAuO4OxAzrStnlsj8EUDd1HtQmFH4Zr+I2ZDQP+DAxw97Kq1qvuIxGJtPVFB5m5rJDpeQWs23GQxARjeI+2jM/O4LKzOsbkPSCiIRSGAT9z98vCr38M4O7/U67NSkLBsSX8ej1wvrvvqGq9CgURqS/uzprtB5iRV8CMvEI27z5Mo8QELuzdnvHZ6VzSL41mjSPZC193ouGYwidALzPrBmwFbgBurNBmMzAamGJm/YAUoCiCNYmI1JqZ0bdjKn07pvIvY/qwLH8fM/IKmLmskHdWbyclOYHRfdMYn53OqD4dGsQorpE+JXUs8FtCp5tOdvdfmNnPgVx3nx4+4+gJoDmhg84/cvfZ1a1TewoiErSyMid30x5m5BUwa3khuw4V07xxEmP6pzE+O4MLerajUVJ0XSQXePdRpCgURCSalJSWMX/9LmbmFfLGitBFci2bJDOmfxpjB6VzQY/oCAiFgohIPSsuKWPu2iJmLS/k7VXbOXCshNSUJMac1ZErB6YHugcRDccURETiSqOkBC7pn8Yl/dM4VlLKh2t3Mmt5IW+t2MbLi/JJTUni0v4dGTco2ICojkJBRCQCGicl/lNA/P2znby+vJDZq7YxdfE/AuLKQR0Z0bN91ASEQkFEJMIaJyUyul8ao/uFAuKjdTt5fdm2kwHRIiWJS/unceXAdEb0akfjpODOYtIxBRGRgBSXlIUCYnkhs1duY//RklBA9Etj7MB0Rvauu4DQgWYRkRhSXFLGR5/vZNayQmav2s6+I8dp0TiJS8J7EGcaEAoFEZEYVVxSxrzPd/J6hYD43iW9uGNk99Nap84+EhGJUY2SEhjVpwOj+nTgl6WhLqZZywvrZdRWhYKISBRLTvxHQNSH6DgHSkREooJCQURETlIoiIjISQoFERE5SaEgIiInKRREROQkhYKIiJykUBARkZNibpgLMysCNp3m4u2AnXVYTqTFUr2xVCvEVr2xVCvEVr2xVCucWb1d3b19TY1iLhTOhJnl1mbsj2gRS/XGUq0QW/XGUq0QW/XGUq1QP/Wq+0hERE5SKIiIyEnxFgqPB13AKYqlemOpVoitemOpVoitemOpVqiHeuPqmIKIiFQv3vYURESkGgoFERE5KW5CwcwuN7M1ZrbOzO4Lup6qmFlnM5tjZqvMbKWZfS/ommrDzBLNbImZzQy6luqYWSsze9nMPjWz1WY2LOiaqmNmPwj/HqwwsxfMLPK33joFZjbZzHaY2Ypy09qY2dtm9ln4Z+sgazyhilofDP8uLDOzV82sVZA1lldZveXm3Wtmbmbt6vp94yIUzCwR+ANwBdAf+KqZ9Q+2qiqVAPe6e3/gfODbUVxred8DVgddRC08DLzp7n2BbKK4ZjPLBL4LDHH3AUAicEOwVX3BFODyCtPuA951917Au+HX0WAKX6z1bWCAuw8C1gI/ru+iqjGFL9aLmXUGxgCbI/GmcREKwHnAOndf7+7FwF+BiQHXVCl3L3T3xeHnBwh9aGUGW1X1zKwTcCXwZNC1VMfMWgIXAn8GcPdid98bbFU1SgKamFkS0BQoCLief+Luc4HdFSZPBJ4OP38auKpei6pCZbW6+2x3Lwm/XAB0qvfCqlDFvy3AQ8CPgIicJRQvoZAJbCn3Op8o/6AFMLMs4Gzg42ArqdFvCf2SlgVdSA26AUXAU+GurifNrFnQRVXF3bcCvyb0jbAQ2Ofus4OtqlbS3L0w/HwbkBZkMafgG8AbQRdRHTObCGx197xIvUe8hELMMbPmwFTg++6+P+h6qmJm44Ad7r4o6FpqIQk4B/iju58NHCJ6uja+INwXP5FQmGUAzczsa8FWdWo8dM571J/3bmb/Tqjr9rmga6mKmTUF/g34z0i+T7yEwlagc7nXncLTopKZJRMKhOfc/ZWg66nBBcAEM9tIqFvuS2b2bLAlVSkfyHf3E3teLxMKiWh1CbDB3Yvc/TjwCjA84JpqY7uZpQOEf+4IuJ5qmdmtwDjgJo/uC7d6EPqCkBf+e+sELDazjnX5JvESCp8Avcysm5k1InSwbnrANVXKzIxQn/dqd/+/oOupibv/2N07uXsWoX/X99w9Kr/Nuvs2YIuZ9QlPGg2sCrCkmmwGzjezpuHfi9FE8YHxcqYDt4Sf3wJMC7CWapnZ5YS6Pie4++Gg66mOuy939w7unhX+e8sHzgn/XteZuAiF8IGke4C3CP1RveTuK4OtqkoXADcT+sa9NPwYG3RRDch3gOfMbBmQA/wy4HqqFN6jeRlYDCwn9PcaVcMymNkLwHygj5nlm9ntwK+AS83sM0J7O78KssYTqqj1EaAF8Hb4b+2xQIssp4p6I/++0b23JCIi9Sku9hRERKR2FAoiInKSQkFERE5SKIiIyEkKBREROUmhIFHDzOaFf2aZ2Y11vO5/q+y9IsXMrjKziFx5WnFb6midA81sSl2vV2KPTkmVqGNmo4B/cfdxp7BMUrmBzSqbf9Ddm9dFfbWsZx6hC6J2nuF6vrBdkdoWM3sH+Ia7R2T0TYkN2lOQqGFmB8NPfwWMDF9M9IPwvRoeNLNPwuPefyvcfpSZfWhm0wlfmWxmr5nZovA9CO4MT/sVoZFGl5rZc+Xfy0IeDN+vYLmZfaXcut+3f9x74bnwVcWY2a8sdL+LZWb260q2ozdw7EQgmNkUM3vMzHLNbG14vKgT96Co1XaVW3dl2/I1M1sYnvYnCw0Vj5kdNLNfmFmemS0ws7Tw9OvC25tnZnPLrX4G0Tc0t9Q3d9dDj6h4AAfDP0cBM8tNvxP4Sfh5YyCX0BgwowgNatetXNs24Z9NgBVA2/LrruS9riE0pn4iodE8NwPp4XXvIzS+TAKhK0tHAG2BNfxjL7tVJdtxG/Cbcq+nAG+G19OL0PAEKaeyXZXVHn7ej9CHeXL49aPA18PPHRgffv5AufdaDmRWrJ/Q1fQzgv490CPYR1Jtw0MkQGOAQWZ2bfh1S0IfrsXAQnffUK7td83sy+HnncPtdlWz7hHAC+5eSmggtw+Ac4H94XXnA5jZUiCL0Jj7R4E/W+guc5XdaS6d0BDd5b3k7mXAZ2a2Huh7ittVldHAYOCT8I5ME/4xAF1xufoWAZeGn38ETDGzlwgNsnfCDkKjsUocUyhILDDgO+7+1j9NDB17OFTh9SXAMHc/bGbvE/pGfrqOlXteCiS5e4mZnUfow/haQmNqfanCckcIfcCXV/HgnVPL7aqBAU+7e2V3DDvu7ifet5Tw37u7TzKzoYRujLTIzAa7+y5C/1ZHavm+0kDpmIJEowOEBik74S3gLgsNKY6Z9bbKb47TEtgTDoS+hG5nesLxE8tX8CHwlXD/fntCd2ZbWFVhFrrPRUt3nwX8gNAtPStaDfSsMO06M0swsx5Ad0JdULXdrorKb8u7wLVm1iG8jjZm1rW6hc2sh7t/7O7/SWiP5sSw8r0JdblJHNOegkSjZUCpmeUR6o9/mFDXzeLwwd4iKr/F45vAJDNbTehDd0G5eY8Dy8xssbvfVG76q8AwII/Qt/cfufu2cKhUpgUwzcxSCH1L/2ElbeYCvzEzK/dNfTOhsEkFJrn7UTN7spbbVdE/bYuZ/QSYbWYJwHHg28CmapZ/0Mx6het/N7ztABcDr9fi/aUB0ympIhFgZg8TOmj7Tvj8/5nu/nLAZVXJzBoDHwAjvJpTe6XhU/eRSGT8EmgadBGnoAtwnwJBtKcgIiInaU9BREROUiiIiMhJCgURETlJoSAiIicpFERE5KT/D/La4HYsM2WLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is finished\n",
      "Test Accuracy: 0.5215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5215,\n",
       " {'W1': <tf.Variable 'W1:0' shape=(5, 5, 3, 8) dtype=float32_ref>,\n",
       "  'W2': <tf.Variable 'W2:0' shape=(2, 2, 8, 16) dtype=float32_ref>})"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_train1 = x_train[0:10000,:]\n",
    "#y_train1 = y_train[0:10000,:]\n",
    "#x_test1  = x_test[0:10000,:] \n",
    "#y_test1  = y_test[0:10000,:]\n",
    "#print(np.shape(x_train1))\n",
    "#print(np.shape(y_train1))\n",
    "#print(np.shape(x_train))\n",
    "#print(np.shape(y_train))\n",
    "model(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
